{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 106874,
          "databundleVersionId": 12959388,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lee2008-cyber/R2_Score/blob/main/R2_Score(Kaggle).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "loiRAamunQYv"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "thapar_summer_school_2025_hack_iii_path = kagglehub.competition_download('thapar-summer-school-2025-hack-iii')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "zKuML8_2nQYx"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-08T16:45:53.513875Z",
          "iopub.execute_input": "2025-07-08T16:45:53.514243Z",
          "iopub.status.idle": "2025-07-08T16:45:53.532316Z",
          "shell.execute_reply.started": "2025-07-08T16:45:53.514208Z",
          "shell.execute_reply": "2025-07-08T16:45:53.53118Z"
        },
        "id": "Db1XS9rznQYy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(\"/kaggle/input/thapar-summer-school-2025-hack-iii/train.csv\")\n",
        "test_df = pd.read_csv(\"/kaggle/input/thapar-summer-school-2025-hack-iii/test.csv\")\n",
        "\n",
        "train_id_col = \"Row#\"\n",
        "test_id_col = \"id\"\n",
        "target_col = \"output\"\n",
        "\n",
        "# Feature engineering\n",
        "def engineer_features(df):\n",
        "    df = df.copy()\n",
        "    df[\"UpperTempRange\"] = df[\"MaxOfUpperTRange\"] - df[\"MinOfUpperTRange\"]\n",
        "    df[\"LowerTempRange\"] = df[\"MaxOfLowerTRange\"] - df[\"MinOfLowerTRange\"]\n",
        "    df[\"RainInteraction\"] = df[\"RainingDays\"] * df[\"AverageRainingDays\"]\n",
        "    df[\"Pollination\"] = df[\"honeybee\"] + df[\"bumbles\"] + df[\"andrena\"] + df[\"osmia\"]\n",
        "    df[\"SizeMassRatio\"] = df[\"fruitmass\"] / (df[\"clonesize\"] + 1e-5)\n",
        "    return df\n",
        "\n",
        "train_df = engineer_features(train_df)\n",
        "test_df = engineer_features(test_df)\n",
        "\n",
        "X = train_df.drop(columns=[train_id_col, target_col])\n",
        "y = train_df[target_col]\n",
        "X_test = test_df.drop(columns=[test_id_col, train_id_col])\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Store base model oof/test predictions\n",
        "oof_lgb, oof_cat, oof_xgb = np.zeros(len(X)), np.zeros(len(X)), np.zeros(len(X))\n",
        "test_lgb, test_cat, test_xgb = np.zeros((len(X_test), 5)), np.zeros((len(X_test), 5)), np.zeros((len(X_test), 5))\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "    print(f\" Fold {fold + 1}\")\n",
        "\n",
        "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    # LightGBM\n",
        "    lgb_train = lgb.Dataset(X_train, y_train)\n",
        "    lgb_val = lgb.Dataset(X_val, y_val)\n",
        "    lgb_model = lgb.train(\n",
        "        {\n",
        "            \"objective\": \"regression\",\n",
        "            \"metric\": \"rmse\",\n",
        "            \"learning_rate\": 0.02,\n",
        "            \"num_leaves\": 64,\n",
        "            \"feature_fraction\": 0.9,\n",
        "            \"bagging_fraction\": 0.75,\n",
        "            \"bagging_freq\": 5,\n",
        "            \"verbosity\": -1,\n",
        "            \"seed\": 42\n",
        "        },\n",
        "        lgb_train,\n",
        "        valid_sets=[lgb_val],\n",
        "        num_boost_round=10000,\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=100),\n",
        "            lgb.log_evaluation(period=0)\n",
        "        ]\n",
        "    )\n",
        "    oof_lgb[val_idx] = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration)\n",
        "    test_lgb[:, fold] = lgb_model.predict(X_test, num_iteration=lgb_model.best_iteration)\n",
        "\n",
        "    # CatBoost\n",
        "    cat_model = CatBoostRegressor(\n",
        "        iterations=2000,\n",
        "        learning_rate=0.03,\n",
        "        depth=6,\n",
        "        loss_function='RMSE',\n",
        "        verbose=0,\n",
        "        random_seed=42\n",
        "    )\n",
        "    cat_model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=100)\n",
        "    oof_cat[val_idx] = cat_model.predict(X_val)\n",
        "    test_cat[:, fold] = cat_model.predict(X_test)\n",
        "\n",
        "    # XGBoost\n",
        "    xgb_model = xgb.XGBRegressor(\n",
        "        n_estimators=2000,\n",
        "        learning_rate=0.02,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        verbosity=0\n",
        "    )\n",
        "    xgb_model.fit(X_train, y_train,\n",
        "                  eval_set=[(X_val, y_val)],\n",
        "                  early_stopping_rounds=100,\n",
        "                  verbose=0)\n",
        "    oof_xgb[val_idx] = xgb_model.predict(X_val)\n",
        "    test_xgb[:, fold] = xgb_model.predict(X_test)\n",
        "\n",
        "# Build meta features\n",
        "oof_meta = pd.DataFrame({\n",
        "    \"lgb\": oof_lgb,\n",
        "    \"cat\": oof_cat,\n",
        "    \"xgb\": oof_xgb\n",
        "})\n",
        "test_meta = pd.DataFrame({\n",
        "    \"lgb\": test_lgb.mean(axis=1),\n",
        "    \"cat\": test_cat.mean(axis=1),\n",
        "    \"xgb\": test_xgb.mean(axis=1)\n",
        "})\n",
        "\n",
        "# Train meta-model\n",
        "meta_model = RidgeCV(alphas=np.logspace(-5, 3, 100))\n",
        "meta_model.fit(oof_meta, y)\n",
        "meta_preds = meta_model.predict(test_meta)\n",
        "cv_r2 = r2_score(y, meta_model.predict(oof_meta))\n",
        "\n",
        "print(f\"\\n Stacking Ridge CV RÂ² Score: {cv_r2:.5f}\")\n",
        "print(f\"Ridge Weights: {meta_model.coef_}\")\n",
        "\n",
        "# Save submission\n",
        "submission = pd.DataFrame({\n",
        "    test_id_col: test_df[test_id_col],\n",
        "    target_col: meta_preds\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"submission.csv saved\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-08T16:45:53.533703Z",
          "iopub.execute_input": "2025-07-08T16:45:53.533975Z",
          "iopub.status.idle": "2025-07-08T16:46:14.577641Z",
          "shell.execute_reply.started": "2025-07-08T16:45:53.533954Z",
          "shell.execute_reply": "2025-07-08T16:46:14.576413Z"
        },
        "id": "IKe7_MannQYy"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}